{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom os import listdir\nfrom numpy import asarray, savez_compressed\nfrom tensorflow.keras.utils import img_to_array, load_img\nimport tensorflow as tf\n\nfrom keras.optimizers import Adam\nfrom keras.initializers import RandomNormal\nfrom keras.models import Model\nfrom keras.layers import Input, Conv2D, LeakyReLU, Activation, Concatenate, BatchNormalization, Conv2DTranspose, Dense\nfrom tensorflow.keras.initializers import RandomNormal\nfrom keras.utils.vis_utils import plot_model\n\nimport warnings\n\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nwarnings.filterwarnings(\"ignore\", category=UserWarning)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-10T14:55:46.718703Z","iopub.execute_input":"2023-09-10T14:55:46.720432Z","iopub.status.idle":"2023-09-10T14:55:46.728074Z","shell.execute_reply.started":"2023-09-10T14:55:46.720201Z","shell.execute_reply":"2023-09-10T14:55:46.727069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Visualization & Processing ","metadata":{}},{"cell_type":"code","source":"# load all images in a directory into memory\ndef load_images(path, size=(256,512)):\n    src_list, tar_list = list(), list()\n    \n    # enumerate filenames in directory, assume all are images\n    for filename in listdir(path):\n        \n        # load and resize the image\n        pixels = load_img(path + filename, target_size=size)\n        \n        # convert to an array\n        pixels = img_to_array(pixels)\n        \n        # split into satellite and map\n        sat_img, map_img = pixels[:, :256], pixels[:, 256:]\n        \n        src_list.append(sat_img)\n        tar_list.append(map_img)\n        \n    return [asarray(src_list), asarray(tar_list)]","metadata":{"execution":{"iopub.status.busy":"2023-09-10T14:52:25.517588Z","iopub.execute_input":"2023-09-10T14:52:25.518334Z","iopub.status.idle":"2023-09-10T14:52:25.525766Z","shell.execute_reply.started":"2023-09-10T14:52:25.518298Z","shell.execute_reply":"2023-09-10T14:52:25.524897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = \"/kaggle/input/pix2pix-maps/train/\"\n\n[src_img, tar_img] = load_images(path)\n\nprint(\"Loaded: \", src_img.shape, tar_img.shape)\n\n# save as compressed numpy array\nfilename = \"maps_256.npz\"\nsavez_compressed(filename, src_img, tar_img)\nprint(\"Saved dataset: \", filename)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-10T14:52:25.527388Z","iopub.execute_input":"2023-09-10T14:52:25.527999Z","iopub.status.idle":"2023-09-10T14:54:34.420348Z","shell.execute_reply.started":"2023-09-10T14:52:25.527966Z","shell.execute_reply":"2023-09-10T14:54:34.419348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pat = \"/kaggle/input/pix2pix-maps/train/1.jpg\"\npix = load_img(pat,target_size=(550, 1000))\na=img_to_array(pix)\na.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-10T14:54:34.425741Z","iopub.execute_input":"2023-09-10T14:54:34.428036Z","iopub.status.idle":"2023-09-10T14:54:34.456332Z","shell.execute_reply.started":"2023-09-10T14:54:34.428000Z","shell.execute_reply":"2023-09-10T14:54:34.455426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.imshow(a/255.)\n\nsat_img, map_img = a[:, :500], a[:, 500:]","metadata":{"execution":{"iopub.status.busy":"2023-09-10T14:54:34.460389Z","iopub.execute_input":"2023-09-10T14:54:34.462621Z","iopub.status.idle":"2023-09-10T14:54:35.178791Z","shell.execute_reply.started":"2023-09-10T14:54:34.462587Z","shell.execute_reply":"2023-09-10T14:54:35.177838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(sat_img/255.)","metadata":{"execution":{"iopub.status.busy":"2023-09-10T14:54:35.179843Z","iopub.execute_input":"2023-09-10T14:54:35.180225Z","iopub.status.idle":"2023-09-10T14:54:35.694760Z","shell.execute_reply.started":"2023-09-10T14:54:35.180192Z","shell.execute_reply":"2023-09-10T14:54:35.693878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(map_img/255.)","metadata":{"execution":{"iopub.status.busy":"2023-09-10T14:54:35.695727Z","iopub.execute_input":"2023-09-10T14:54:35.696060Z","iopub.status.idle":"2023-09-10T14:54:36.152698Z","shell.execute_reply.started":"2023-09-10T14:54:35.696025Z","shell.execute_reply":"2023-09-10T14:54:36.151802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from numpy import load\nfrom matplotlib import pyplot\n# load the face dataset\ndata = load(\"/kaggle/working/maps_256.npz\")\nsrc_images, tar_images = data[\"arr_0\"], data[\"arr_1\"]\nprint(\"Loaded: \", src_images.shape, tar_images.shape)\n# plot source images\nn_samples = 3\nfor i in range(n_samples):\n    pyplot.subplot(2, n_samples, 1 + i)\n    pyplot.axis(\"off\")\n    pyplot.imshow(src_images[i].astype(\"uint8\"))\n# plot target image\nfor i in range(n_samples):\n    pyplot.subplot(2, n_samples, 1 + n_samples + i)\n    pyplot.axis(\"off\")\n    pyplot.imshow(tar_images[i].astype(\"uint8\"))\n    pyplot.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-10T14:54:36.154193Z","iopub.execute_input":"2023-09-10T14:54:36.155210Z","iopub.status.idle":"2023-09-10T14:54:42.445022Z","shell.execute_reply.started":"2023-09-10T14:54:36.155171Z","shell.execute_reply":"2023-09-10T14:54:42.443718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Configuration Starts here","metadata":{}},{"cell_type":"markdown","source":"## Discriminator Model\nThe discriminator is a deep convolutional neural network that performs image classification.\nSpecifically, conditional-image classification. It takes both the source image (e.g. satellite photo)\nand the target image (e.g. Google maps image) as input and predicts the likelihood of whether\ntarget image is a real or fake translation of the source image. The discriminator design is based\non the effective receptive field of the model, which defines the relationship between one output\nof the model to the number of pixels in the input image. This is called a PatchGAN model and\nis carefully designed so that each output prediction of the model maps to a 70 × 70 square or\npatch of the input image. The benefit of this approach is that the same model can be applied\nto input images of different sizes, e.g. larger or smaller than 256 × 256 pixels.","metadata":{}},{"cell_type":"code","source":"from keras.layers import Input, Conv2D, LeakyReLU, Activation, Concatenate, BatchNormalization, Conv2DTranspose, Dense, Dropout\n","metadata":{"execution":{"iopub.status.busy":"2023-09-10T14:54:42.446637Z","iopub.execute_input":"2023-09-10T14:54:42.447122Z","iopub.status.idle":"2023-09-10T14:54:42.453063Z","shell.execute_reply.started":"2023-09-10T14:54:42.447085Z","shell.execute_reply":"2023-09-10T14:54:42.452031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def discriminator(image_shape=[256, 256, 3]):\n    \n    # An idle initializers for neural network (that's what paper say let's see)\n    init = RandomNormal(stddev=0.02)\n    \n    # size of the source image input\n    inp = tf.keras.layers.Input(shape=image_shape, name='input_image')\n\n    # size of target image input\n    tar = tf.keras.layers.Input(shape=image_shape, name='target_image')\n\n    \n    merge = Concatenate()([inp,tar]) # (batch_size, 256, 256, channels*2)\n    \n    # first hidden layer : C64\n    one = Conv2D(64,kernel_size=(4,4),strides=(2,2), padding=\"same\",kernel_initializer=init)(merge)\n    avt1 = LeakyReLU(0.2)(one)\n    \n    # second hidden layer : C128\n    two = Conv2D(128,kernel_size=(4,4),strides=(2,2), padding=\"same\",kernel_initializer=init)(avt1)\n    d = BatchNormalization()(two)\n    avt2 = LeakyReLU(alpha=0.2)(d)\n    \n    # third hidden layer : C256\n    three = Conv2D(256,kernel_size=(4,4),strides=(2,2), padding=\"same\",kernel_initializer=init)(avt2)\n    d2 = BatchNormalization()(three)\n    avt3 = LeakyReLU(alpha=0.2)(d2)\n    \n    # fourth hidden layer : C512\n    four = Conv2D(512,kernel_size=(4,4),strides=(2,2), padding=\"same\",kernel_initializer=init)(avt3)\n    d3 = BatchNormalization()(four)\n    avt4 = LeakyReLU(alpha=0.2)(d3)\n    \n    # second-last layer : C512\n    d = Conv2D(512, (4,4), padding=\"same\", kernel_initializer=init)(avt4)\n    d = BatchNormalization()(d)\n    d = LeakyReLU(alpha=0.2)(d)\n\n    # patch output/hidden layer \n    out = Conv2D(1,(4,4),padding=\"same\",kernel_initializer=init)(d)\n    patch_out = Activation(\"sigmoid\")(out)\n    \n    model = Model([inp,tar],patch_out)\n    opt = Adam(learning_rate=0.0002, beta_1=0.5)\n    model.compile(optimizer=opt, loss=\"binary_crossentropy\", loss_weights=0.5)\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2023-09-10T14:54:42.459649Z","iopub.execute_input":"2023-09-10T14:54:42.460268Z","iopub.status.idle":"2023-09-10T14:54:42.709235Z","shell.execute_reply.started":"2023-09-10T14:54:42.460216Z","shell.execute_reply":"2023-09-10T14:54:42.707944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_shape = (256,256,3)\n# create the model\nmodel = discriminator(image_shape)\n# summarize the model\nmodel.summary()\n# plot the model\nplot_model(model, show_shapes=True,show_layer_names=True)","metadata":{"_kg_hide-input":false,"_kg_hide-output":false,"scrolled":true,"execution":{"iopub.status.busy":"2023-09-10T14:55:59.217747Z","iopub.execute_input":"2023-09-10T14:55:59.218445Z","iopub.status.idle":"2023-09-10T14:56:05.850721Z","shell.execute_reply.started":"2023-09-10T14:55:59.218410Z","shell.execute_reply":"2023-09-10T14:56:05.849671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Generator Model: Encoder block utility","metadata":{}},{"cell_type":"code","source":"def encoder_block(layer_in, units, batchnorm = True):\n    \n    init = RandomNormal(stddev=0.02)\n    \n    enc = Conv2D(units,(4,4),strides=(2,2),padding=\"same\",kernel_initializer=init)(layer_in)\n    \n    # conditionally add batch norm, as this function is utility\n    if batchnorm:\n        enc = BatchNormalization()(enc)\n    \n    g = LeakyReLU(alpha=0.2)(enc)\n    \n    return g\n    ","metadata":{"execution":{"iopub.status.busy":"2023-09-10T14:56:05.852737Z","iopub.execute_input":"2023-09-10T14:56:05.853392Z","iopub.status.idle":"2023-09-10T14:56:05.860815Z","shell.execute_reply.started":"2023-09-10T14:56:05.853337Z","shell.execute_reply":"2023-09-10T14:56:05.859427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Generator Model: Decoder Block utility","metadata":{}},{"cell_type":"code","source":"def decoder_block(layer_in, units, skip_in, dropout = True):\n    \n    init = RandomNormal(stddev=0.02)\n    \n    dec = Conv2DTranspose(units,(4,4),strides=(2,2),padding=\"same\",kernel_initializer=init)(layer_in)\n    \n    g = BatchNormalization()(dec, training=True)\n\n    # conditionally add batch norm, as this function is utility\n    if dropout:\n        g = Dropout(0.5)(g, training=True)\n        \n    # merge with skip connection\n    g = Concatenate()([g, skip_in])\n    # relu activation\n    g = Activation(\"relu\")(g)\n\n    return g\n    ","metadata":{"execution":{"iopub.status.busy":"2023-09-10T14:56:06.590823Z","iopub.execute_input":"2023-09-10T14:56:06.591223Z","iopub.status.idle":"2023-09-10T14:56:06.598140Z","shell.execute_reply.started":"2023-09-10T14:56:06.591193Z","shell.execute_reply":"2023-09-10T14:56:06.597093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Generator Model Definition: U-net struture\nThe generator model is more complex than the discriminator model. The generator is\nan encoder-decoder model using a U-Net architecture. The model takes a source image (e.g.\nsatellite photo) and generates a target image (e.g. Google maps image). It does this by first\ndownsampling or encoding the input image down to a bottleneck layer, then upsampling or\ndecoding the bottleneck representation to the size of the output image","metadata":{}},{"cell_type":"code","source":"def generator(image_shape=(256,256,3)):\n    \n    init = RandomNormal(stddev=0.02)\n    \n    input_img = Input(shape=image_shape)\n    \n    # Encoder Block\n    e1 = encoder_block(input_img, 64, batchnorm=False)\n    e2 = encoder_block(e1,128)\n    e3 = encoder_block(e2,256)\n    e4 = encoder_block(e3,512)\n    e5 = encoder_block(e4,512)\n    e6 = encoder_block(e5,512)\n    e7 = encoder_block(e6,512)\n    \n    # bottleneck, no batch norm and relu\n    b = Conv2D(512, (4,4), strides=(2,2), padding=\"same\", kernel_initializer=init)(e7)\n    b = Activation(\"relu\")(b)\n    \n    # Decoder Block\n    d1 = decoder_block(b,512,e7)\n    d2 = decoder_block(d1,512,e6)\n    d3 = decoder_block(d2,512,e5)\n    d4 = decoder_block(d3,512,e4,dropout=False)\n    d5 = decoder_block(d4,256,e3,dropout=False)\n    d6 = decoder_block(d5,128,e2,dropout=False)\n    d7 = decoder_block(d6,64,e1,dropout=False)\n\n    # output\n    g = Conv2DTranspose(3, (4,4), strides=(2,2), padding=\"same\", kernel_initializer=init)(d7)\n    out_image = Activation(\"tanh\")(g)\n    \n    # define model\n    model = Model(input_img, out_image)\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-09-10T14:56:07.399274Z","iopub.execute_input":"2023-09-10T14:56:07.399638Z","iopub.status.idle":"2023-09-10T14:56:07.410106Z","shell.execute_reply.started":"2023-09-10T14:56:07.399607Z","shell.execute_reply":"2023-09-10T14:56:07.408955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = generator()\nplot_model(model)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-09-10T14:56:07.846220Z","iopub.execute_input":"2023-09-10T14:56:07.846552Z","iopub.status.idle":"2023-09-10T14:56:08.961965Z","shell.execute_reply.started":"2023-09-10T14:56:07.846522Z","shell.execute_reply":"2023-09-10T14:56:08.960968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pix2pix_model(g_model, d_model, input_img):\n    \n    d_model.trainable = False\n    \n    in_img = Input(shape=input_img)\n    \n    gen_out = g_model(in_img)\n    \n    dis_out = d_model([in_img, gen_out])\n    \n    model = Model(in_img, [gen_out, dis_out])\n    \n    opt = Adam(learning_rate=0.0002, beta_1=0.5)\n    \n    model.compile(optimizer=opt, loss=['binary_crossentropy','mae'], loss_weights=[1,100])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2023-09-10T14:56:08.963783Z","iopub.execute_input":"2023-09-10T14:56:08.968150Z","iopub.status.idle":"2023-09-10T14:56:08.978792Z","shell.execute_reply.started":"2023-09-10T14:56:08.968095Z","shell.execute_reply":"2023-09-10T14:56:08.977530Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load and prepare training images\ndef load_real_samples(filename):\n    # load the compressed arrays\n    data = np.load(filename)\n    # unpack the arrays\n    X1, X2 = data[\"arr_0\"], data[\"arr_1\"]\n    # scale from [0,255] to [-1,1]\n    X1 = (X1 - 127.5) / 127.5\n    X2 = (X2 - 127.5) / 127.5\n    return [X1, X2]\n","metadata":{"execution":{"iopub.status.busy":"2023-09-10T14:56:08.980181Z","iopub.execute_input":"2023-09-10T14:56:08.981150Z","iopub.status.idle":"2023-09-10T14:56:08.991767Z","shell.execute_reply.started":"2023-09-10T14:56:08.981105Z","shell.execute_reply":"2023-09-10T14:56:08.990937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# select a batch of random samples, returns images and target\ndef generate_real_samples(dataset, n_samples, patch_shape):\n    # unpack dataset\n    trainA, trainB = dataset\n    # choose random instances\n    ix = np.random.randint(0, trainA.shape[0], n_samples)\n    # retrieve selected images\n    X1, X2 = trainA[ix], trainB[ix]\n    # generate \"real\" class labels (1)\n    y = np.ones((n_samples, patch_shape, patch_shape, 1))\n    return [X1, X2], y\n","metadata":{"execution":{"iopub.status.busy":"2023-09-10T14:56:11.056112Z","iopub.execute_input":"2023-09-10T14:56:11.056472Z","iopub.status.idle":"2023-09-10T14:56:11.063166Z","shell.execute_reply.started":"2023-09-10T14:56:11.056442Z","shell.execute_reply":"2023-09-10T14:56:11.062215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# generate a batch of images, returns images and targets\ndef generate_fake_samples(g_model, samples, patch_shape):\n    # generate fake instance\n    X = g_model.predict(samples)\n    # create \"fake\" class labels (0)\n    y = np.zeros((len(X), patch_shape, patch_shape, 1))\n    return X, y\n","metadata":{"execution":{"iopub.status.busy":"2023-09-10T14:56:11.586065Z","iopub.execute_input":"2023-09-10T14:56:11.586874Z","iopub.status.idle":"2023-09-10T14:56:11.591994Z","shell.execute_reply.started":"2023-09-10T14:56:11.586839Z","shell.execute_reply":"2023-09-10T14:56:11.591015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def summarize_performance(step, g_model, dataset, n_samples=3):\n    # select a sample of input images\n    [X_realA, X_realB], _ = generate_real_samples(dataset, n_samples, 1)\n    # generate a batch of fake samples\n    X_fakeB, _ = generate_fake_samples(g_model, X_realA, 1)\n    # scale all pixels from [-1,1] to [0,1]\n    X_realA = (X_realA + 1) / 2.0\n    X_realB = (X_realB + 1) / 2.0\n    X_fakeB = (X_fakeB + 1) / 2.0\n    # plot real source images\n    for i in range(n_samples):\n        pyplot.subplot(3, n_samples, 1 + i)\n        pyplot.axis(\"off\")\n        pyplot.imshow(X_realA[i])\n    # plot generated target image\n    for i in range(n_samples):\n        pyplot.subplot(3, n_samples, 1 + n_samples + i)\n        pyplot.axis(\"off\")\n        pyplot.imshow(X_fakeB[i])\n    # plot real target image\n    for i in range(n_samples):\n        pyplot.subplot(3, n_samples, 1 + n_samples*2 + i)\n        pyplot.axis(\"off\")\n        pyplot.imshow(X_realB[i])\n    # save plot to file\n    filename1 = \"plot_%06d.png\" % (step+1)\n    pyplot.savefig(filename1)\n    pyplot.close()\n    # save the generator model\n    filename2 = \"model_%06d.h5\" % (step+1)\n    g_model.save(filename2)\n    print(\">Saved: %s and %s\" % (filename1, filename2))","metadata":{"execution":{"iopub.status.busy":"2023-09-10T14:56:12.094040Z","iopub.execute_input":"2023-09-10T14:56:12.094760Z","iopub.status.idle":"2023-09-10T14:56:12.105658Z","shell.execute_reply.started":"2023-09-10T14:56:12.094727Z","shell.execute_reply":"2023-09-10T14:56:12.104544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train pix2pix models\ndef train(d_model, g_model, gan_model, dataset, n_epochs=100, n_batch=1):\n    # determine the output square shape of the discriminator\n    n_patch = d_model.output_shape[1]\n    # unpack dataset\n    trainA, trainB = dataset\n    # calculate the number of batches per training epoch\n    bat_per_epo = int(len(trainA) / n_batch)\n    # calculate the number of training iterations\n    n_steps = bat_per_epo * n_epochs\n    # manually enumerate epochs\n    for i in range(n_steps):\n        # select a batch of real samples\n        [X_realA, X_realB], y_real = generate_real_samples(dataset, n_batch, n_patch)\n        # generate a batch of fake samples\n        X_fakeB, y_fake = generate_fake_samples(g_model, X_realA, n_patch)\n        # update discriminator for real samples\n        d_loss1 = d_model.train_on_batch([X_realA, X_realB], y_real)\n        # update discriminator for generated samples\n        d_loss2 = d_model.train_on_batch([X_realA, X_fakeB], y_fake)\n        # update the generator\n        g_loss, _, _ = gan_model.train_on_batch(X_realA, [y_real, X_realB])\n        # summarize performance\n        print(\">%d, d1[%.3f] d2[%.3f] g[%.3f]\" % (i+1, d_loss1, d_loss2, g_loss))\n        # summarize model performance\n        if (i+1) % (bat_per_epo * 10) == 0:\n            summarize_performance(i, g_model, dataset)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-10T14:56:12.489610Z","iopub.execute_input":"2023-09-10T14:56:12.489970Z","iopub.status.idle":"2023-09-10T14:56:12.498994Z","shell.execute_reply.started":"2023-09-10T14:56:12.489939Z","shell.execute_reply":"2023-09-10T14:56:12.498002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = load_real_samples('/kaggle/working/maps_256.npz')\nprint(f'Loaded data size : {dataset[0].shape}, {dataset[1].shape}')\n\nimg_shape = dataset[0].shape[1:]\n\nd_model = discriminator(img_shape)\ng_model = generator(img_shape)\n\ngan_model = pix2pix_model(g_model,d_model,img_shape)\n\ntrain(d_model,g_model=g_model,gan_model=gan_model,dataset=dataset,n_epochs=50)","metadata":{"execution":{"iopub.status.busy":"2023-09-10T14:56:14.645864Z","iopub.execute_input":"2023-09-10T14:56:14.646237Z","iopub.status.idle":"2023-09-10T14:56:37.506534Z","shell.execute_reply.started":"2023-09-10T14:56:14.646207Z","shell.execute_reply":"2023-09-10T14:56:37.504249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}],"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}}